---
layout: post
title: '[CVPR 2023] itKD: Interchange Transfer-based Knowledge Distillation for 3D Object Detection'
date: 2025-03-02 15:00 +0800
last_modified_at: 2025-03-02 15:00 +0800
tags: [jekyll theme, jekyll, tutorial]
toc:  true
---
## Abstract
- 포인트 클라우드 기반의 3D 물체 감지기는 최근 눈부신 발전을 이룸. 그러나 대부분의 연구는 계산 효율성을 고려하지 않고 정확성만을 향상시키기 위한 네트워크 아키텍처 개발에 국한되어 있음.
- 본 논문에서는 먼저 교환 전송 기반 지식 증류를 통해 채널별 압축 및 압축 해제로 구성된 AutoEncoder 스타일 프레임워크를 제안함. 
- 교사 네트워크의 지도 보기 feature을 학습하려면 교사와 학생 네트워크의 feature이 shared AutoEncoder를 통해 독립적으로 전달됨. 여기서는 학생과 교사 네트워크 모두의 채널별 압축 지식을 일종의 정규화로 묶는 압축 표현 손실을 사용함.
- 마지막으로 Multi-head self-attention 메커니즘을 통해 도출된 3차원 object detection 정보와 일치하는 head attention loss을 제시함. 

## Introduction

(figure 1 사진)

- 2D 데이터와 3D 데이터의 차이점을 자세히 살펴보면 2D object detection는 일반적으로 해당 모양과 함께 고유한 색상 정보를 기반으로 2D 객체 위치를 예측하는 데 큰 차이가 있지만, 3D object detection는 3D 객체 상자만 구성된 입력에서 추정함.
- 3D 포인트 클라우드의 수는 거리와 폐색 유무에 따라 달라짐.
- 또 다른 과제는 2D object detection에 비해 3D object detection이 3D box와 같은 detection head 구성 요소 및 방향이 더 많다는 것입니다. 이러한 감지 헤드는 서로 높은 상관관계가 있으며 서로 다른 3D 특성을 나타냅니다. 
- 이를 고려하여 증류된 지식을 안내하는 것이 필요하여 itKD(Interchange Transferbased KD) 방법을 제안


## Related work

###  3D Object Detection based on Point Cloud
- grid-based, point-based, hybrid-based
- 이 논문에서는 CenterPoint를 backbone으로 사용

### Knowledge Distillation
- 포인트 클라우드 기반 3차원 객체 detection에 대한 KD 연구는 아직까지 거의 없으며, 몇몇 연구에서는 성능을 높이는데 초점.
- 반면, 본 논문에서는 3D object detection에 KD를 사용하여 학생 네트워크를 더 가볍게 만들거나 계산 복잡도를 낮추는 방법에 더 관심을 둠.

## Methodology

(그림 삽입)

- 3D 포인트 클라우드 객체 detection ​​방법은 일반적으로 포인트 클라우드 인코더, 백본 네트워크 및 detection 헤드의 세 가지 구성 요소로 구성됨.
- 본 논문에서는 CenterPoint [43] 네트워크를 백본 아키텍처로 사용. 
- 백본 네트워크의 매개변수 크기는 3차원 객체 검출기의 구성 요소 중 가장 크므로 효율적인 네트워크를 위해 백본 네트워크의 채널 크기를 줄여 학생 네트워크를 구축하는 것을 목표로 함.
- 3D 검출기의 전체 매개변수 크기는 약 5.2M이고 백본 크기는 약 4.8M

### Interchange Transfer

(그림 삽입)


- 3D 감지에 관한 의미 있는 증류 지식을 교사로부터 학생 네트워크로 효과적으로 전달하기 위해 Channel-wise Autoencoder 사용. 
- 객체의 위치 정보를 학생 네트워크로 대략적으로 안내하기 위한 압축 표현 손실을 제안

(수식 삽입)

- 디코더는 압축된 특징으로부터 채널 방향의 미세한 맵뷰 특징을 재구성.
- 재구성된 특징은 반대 네트워크로 안내됨.
- 학생 네트워크에서 재구성된 미세한 특징을 교사 네트워크 Mt의 출력과 유사하도록 학습
- 또한, 교사 네트워크에서 재구성된 미세한 특징은 동시에 학생의 출력 Ms를 안내

(수식 삽입)

### Head Relation-Aware Self-Attention

(그림 삽입)
- 기본적으로 3D object detection 모델은 detection head에 다양한 유형의 3D 개체 특성을 가지고 있음.
- 물체의 위치, 크기, 방향은 서로 다른 속성이지만, 같은 물체에서 나오기 때문에 필연적으로 서로 상관관계가 있다고 함.
- 그러나 기존 KD 방법은 detection head 간의 관계를 고려하지 않고 학생 네트워크가 교사 네트워크의 출력을 어떻게 직접적으로 모방하는지에만 관심이 있음.
- 이 문제를 극복하기 위해 본 논문은 KD의 주요 요소로 detection head의 관계를 활용

(그림 삽입)
- multi-head self-attention  기반
- i-th instance feature는 클래스별 히트맵, 서브 복셀 위치 세분화, 지면 위 높이, 3D 크기, 회전 각도와 같은 여러 객체 속성을 가짐.
- 총 n개의 객체가 있을 때 이를 결합하여 객체 중심 헤드 특징을 만듭니다. 우리는 scaled dot product attention 입력인 쿼리, 키, 값에 대해 차원 n의 동일한 객체 중심 헤드 특징 v를 사용
(수식 삽입)

- head relation-aware self-attention는 head 간 관계와 head 내 관계에 대한 두 가지 서로 다른 셀프 어텐션으로 구성
- 헤드 간 관계에 기반한 셀프 어텐션

- 개별 detection head를 사용하여 intra-head 관계에 대한 셀프 어텐션을 제안
- 다양한 속성(예: 방향, 크기 등)에 맞게 설계된 개별 감지 헤드의 로컬 관계만 사용하여 주의를 수행하고 이를 연결

- Fusion 레이어(1×1 conv)를 적용하여 최종 attention 점수 계산
- 학생 네트워크는 아래의 손실함수로 교사 네트워크의 다중 탐지 헤드 간의 관계를 학습
- 최종 손실함수 (a,b는 1로 설정)

## Experimental Results and Discussions

### Environment Settings
- Waymo : 자율 주행을 위한 대규모 데이터 세트 중 하나
- 다양한 도시 및 교외 지역에 걸쳐 동기화되고 보정된 고품질 LiDAR 및 카메라로 캡처됨. 
- 반경 75m 내의 모든 객체를 감지하여 얻은 798개의 훈련 장면과 202개의 검증 장면을 제공(총 3개의 개체 범주(예: 차량, 보행자 및 자전거 타는 사람) 포함)
- mAP, mAPH로 비교. (mAPH는 heading에 더 많은 가중치를 부여하여 물체의 방향을 설명)


- nuScenes : 1,000개의 운전 시퀀스가 ​​포함되는 자율주행용 데이터.
- 700, 150, 150개의 시퀀스가 ​​훈련, 검증, 테스트에 각각 사용되며, 각 시퀀스는 32레인 LiDAR를 사용하여 20FPS로 약 20초 동안 캡처됨.
- 평가 지표는 평균 정밀도(AP)와 NuScene 감지 점수(NDS)
- NDS는 상자 위치, 크기, 방향, 속성 및 속도 측면에서 detection 품질을 측정하는 mAP 및 참양성 측정항목의 가중 평균

Implementation details
- Teacher 네트워크인 Pillar 기반 CenterPoint [43]에 따라 가중치 감쇠가 0.01인 Adam 옵티마이저 [12]와 코사인 어닐링 전략 [27]을 사용하여 학습 속도를 조정합니다. 초기 학습률은 0.0003, 최대 학습률은 0.003, 운동량은 0.95로 설정했습니다. 
- 배치 크기가 32인 8×V100 GPU에서 36 epoch 동안 훈련
- Waymo 데이터 세트의 경우 X 및 Y축에 대해 감지 범위를 [-74.88m, 74.88m], [-2m, 4m]로 설정했습니다. ]는 Z축의 경우 그리드 크기는 (0.32m, 0.32m)입니다. NuScenes 데이터세트에 대한 실험에서는 (0.2m, 0.2m) 그리드를 사용하고 X축과 Y축의 감지 범위를 [-51.2m, 51.2m], Z축의 감지 범위를 [-5m, 3m]로 설정했습니다. , 그리드 크기는 (0.2m, 0.2m)입니다. 
- 교사 네트워크에 비해 학생 네트워크는 백본 네트워크의 채널 용량이 1/4 적습니다. 
- 우리의 채널별 오토인코더는 인코더로 3개의 1×1 콘볼루션 레이어와 디코더로 3개의 1×1 콘볼루션 레이어로 구성
- 필터 수는 인코더 레이어에서 128, 64, 32, 디코더 레이어에서 64, 128, 384이다. 
- 학생의 입력 버퍼 계층은 채널 크기를 196에서 384로 늘리고 교사의 출력 버퍼 계층은 채널 크기를 384에서 196으로 줄입니다.

### Overall KD Performance Comparison
총 7가지 KD 방법을 reimplement
Baseline : Kullback-Leibler(KL) 발산 손실[9]을 중앙 히트맵 헤드에 적용하고 l1 손실을 다른 회귀 헤드에 적용
FitNet : 레이어의 중간 출력을 모방하는 방법이며 단순화를 위해 이를 백본의 출력에 적용
EOD-KD : 2D object detection KD 중 하나, 3D로 간단히 확장
TOFD : 3D classification 기반 KD,  감지 작업에 적용
SE-SSD, Object DGCNN, SparseKD : 3D object detection KD

### Ablation Studies